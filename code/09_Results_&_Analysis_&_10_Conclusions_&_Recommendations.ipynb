{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9be44b",
   "metadata": {},
   "source": [
    "## 9. Results & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b3437",
   "metadata": {},
   "source": [
    "### 9.1 \"The Metamorphosis\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5dcf2",
   "metadata": {},
   "source": [
    "| Text       |Score Type | Ref Model | Ref Model LS |Opt Model |\n",
    "|:-----------------------:|:----------------:|:----------------:|:------------:|:---------:|\n",
    "|The Metamorphosis   |Cumulative 1-gram      |      0.2549       |    0.2871     | 0.2353   |     \n",
    "|                    |Cumulative 2-gram      |      0.1428    |  0.0758    | 0.1815  |    \n",
    "|                    |Cumulative 3-gram      |     0.0963    |   0.0399   | 0.1621  |    \n",
    "|                    |Cumulative 4-gram      |      0.0645      |    0.0155     | 0.1432|   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc79437",
   "metadata": {},
   "source": [
    "Table 1: BLEU Scores for \"The Metamorphosis\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf9f27d",
   "metadata": {},
   "source": [
    "| Text       |Score Type | Metric | Ref Model | Ref Model LS |Opt Model |\n",
    "|:-----------------------:|:----------------:|:----------------:|:------------:|:---------:|:---------:|\n",
    "|The Metamorphosis   |Rouge-1      |      Recall       |    0.2500     | 0.2740  |    0.3000    |\n",
    "|                    |             |      Precision    |    0.2941     | 0.2778   |     0.2791   | \n",
    "|                    |             |      F1           |   0.2703     | 0.2759   |     0.2892    |\n",
    "|                    |Rouge-2      |      Recall       |   0.0800    | 0.0200  |    0.1400    |\n",
    "|                    |             |      Precision    |    0.0975   | 0.0208   |    0.1429    | \n",
    "|                    |             |      F1           |    0.0879     | 0.0204   |   0.1414    |\n",
    "|                    |Rouge-l      |      Recall       |    0.2000     | 0.1233  |     0.2500    |\n",
    "|                    |             |      Precision    |    0.2353     | 0.1250   |     0.2326   | \n",
    "|                    |             |      F1           |    0.2162    | 0.1241   |    0.2410    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d0084",
   "metadata": {},
   "source": [
    "Table 2: ROGUE Scores of \"The Metamorphosis\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b238861",
   "metadata": {},
   "source": [
    "From the Table 1, we observe that the optimized model performs better than the reference model. Looking at the difference cumulative n-gram scores, the 1-gram score for the optimized model is slightly lower than the reference model. However, the 2-gram, 3-gram and 4-gram scores are significantly higher. This shows that the generated text sequences from the optimized model have a higher similarity to the reference text. \n",
    "\n",
    "Several hyperparameters were tuned in the reference model to derive the optimized model. First, the number of hidden neurons (units) was increased from 100 to 150. This increased the accuracy of the model but did not significantly contribute to better BLEU or ROUGE scores. Subsequently, dropout layers were added after each LSTM layer to reduce overfitting. In tuning the degree of dropout, a rate of 0.2 was found to be better than 0.1 based on literature review and testing. This addition only had a slight improvement on model performance. After which, a unidirectional LSTM layer was replaced with a bidirectional LSTM layer to observe if sutyding the past and future inputs helped. This addition produced a significant increase in the BLEU and ROGUE scores for the optimized model. \n",
    "\n",
    "The last two hyperparameters explored were batch size and epoch number. Increasing the number of epochs from 100 to 150 increased the accuracy of the model but did not increase the BLEU or ROGUE scores. A more impactful change was decreasing the batch size from 128 to 64, which increased the number of iterations per epoch. This significantly lowered the loss function score and improved the BLEU and ROGUE scores.\n",
    "\n",
    "When analyzing the ROGUE scores in Table 2, the optimized model shows better scores than the reference model. Since F1-score  takes into consideration both the recall and precision of the model, it can be a good measure of model performance. The F1-score for Rouge-1 is 0.2892 for the optimized model and 0.2703 for the reference model. The F1-score for Rouge-2 is 0.1414 for the optimized model and 0.0879 for the reference model. The F1-score for Rouge-l is 0.2410 for the optimized model and 0.2162 for the reference model. This shows that the optimized model shows significant improvement than the reference model.\n",
    "\n",
    "Besides hyperparameter tuning, the sequence length was explored to see if a longer input sequence would result in better model performance. However, it can be seen from the BLEU scores above that increasing the sequence length decreased model performance by about 50%. This was also supported by the lower ROGUE scores when a sequence length of 100 words was used. Hence, it is better to use a shorter sequence length to achieve better results.\n",
    "\n",
    "Having explored the aforementioned hyperparameters, the two most significant changes that improved model performance were introducing a bidirectional LSTM layer and decreasing the batch size from 128 to 64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f27110",
   "metadata": {},
   "source": [
    "### 9.2 \"The Castle\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca32b5",
   "metadata": {},
   "source": [
    "| Text       |Score Type |  Ref Model | Ref Model LS |Opt Model |\n",
    "|:-----------------------:|:----------------:|:----------------:|:------------:|:---------:|\n",
    "|The Castle          |Cumulative 1-gram      |      0.1960     |    0.2574    | 0.2352   |    \n",
    "|                    |Cumulative 2-gram      |     0.0626      |    0.0507    | 0.0970  |     \n",
    "|                    |Cumulative 3-gram      |     0.0208     |    0.0143    | 0.0277| \n",
    "|                    |Cumulative 4-gram      |     0.0113       |    0.0071     | 0.0141  |   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f2d8b",
   "metadata": {},
   "source": [
    "Table 3: BLEU Scores for \"The Castle\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a571b",
   "metadata": {},
   "source": [
    "| Text       |Score Type | Metric | Ref Model | Ref Model LS |Opt Model |\n",
    "|:-----------------------:|:----------------:|:----------------:|:------------:|:---------:|:---------:|\n",
    "|The Castle          |Rouge-1      |      Recall       |    0.1521    | 0.2615   |    0.2391  |\n",
    "|                    |             |      Precision    |    0.1891     | 0.2428  |   0.2750   | \n",
    "|                    |             |      F1           |    0.1686    | 0.2519  |     0.2558    |\n",
    "|                    |Rouge-2      |      Recall       |    0.0200     | 0.0108   |     0.0400    |\n",
    "|                    |             |      Precision    |    0.0208     | 0.0105  |     0.0408    | \n",
    "|                    |             |      F1           |    0.0204     | 0.0106   |     0.0404    |\n",
    "|                    |Rouge-l      |      Recall       |    0.1086     | 0.1077   |    0.2500    |\n",
    "|                    |             |      Precision    |    0.1351   | 0.1000   |    0.2326  | \n",
    "|                    |             |      F1           |    0.1204     | 0.1037   |     0.2410   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce3346",
   "metadata": {},
   "source": [
    "Table 4: ROUGE Scores for \"The Castle\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e52c3",
   "metadata": {},
   "source": [
    "To observe how the text generation model performs on unseen text from the same author, we used an excerpt from \"The Castle\" by Frank Kafka and analyzed the BLEU and ROGUE scores. As expected, the BLEU and ROGUE scores for \"The Castle\" were lower than \"The Metamorphosis\" since the word dictionary was derived from the latter. As a result, some of the words used in \"The Castle\" may not be found in the model's word dictionary. This could be addressed by using GLoVe embedding with uses a global dictionary of words rather than a limited vocabulary derived from the reference text. \n",
    "\n",
    "When comparing the performance of the optimized model to the reference model, we can see that the optimized model shows better BLEU and ROGUE scores. However, when we review the text generated after inputting the excerpt from \"The Castle\", the character name in the output sequence still resembles that from \"The Metamorphosis\", refering to the main character, Gregor. Similarly, the setting of the story references the house in \"The Metamorphosis\" rather than the village in \"The Castle\".\n",
    "\n",
    "Perhaps multiple texts can be used to train the text generation model. This may help in the generalization of the model and help it generate multiple characters and scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae12d9",
   "metadata": {},
   "source": [
    "### 9.3 \"Kafka on the Shore\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a649a81b",
   "metadata": {},
   "source": [
    "| Text       |Score Type | Ref Model | Ref Model LS |Opt Model |\n",
    "|:-----------------------:|:----------------:|:----------------:|:------------:|:---------:|\n",
    "|Kafka on the Shore  |Cumulative 1-gram      |     0.0392     |   0.1485  | 0.0392   |   \n",
    "|                    |Cumulative 2-gram      |    0.0088      |    0.0121    | 0.0088  | \n",
    "|                    |Cumulative 3-gram      |    0.0057       |   0.0056   | 0.0057   |    \n",
    "|                    |Cumulative 4-gram      |    0.0043      |   0.0035     | 0.0043   |    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69001536",
   "metadata": {},
   "source": [
    "Table 5: BLEU Scores for \"Kafka on the Shore\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f20e0a",
   "metadata": {},
   "source": [
    "| Text       |Score Type | Metric | Ref Model | Ref Model LS |Opt Model |\n",
    "|:-----------------------:|:----------------:|:----------------:|:------------:|:---------:|:---------:|\n",
    "|Kafka on the Shore  |Rouge-1      |      Recall       |    0.0444     | 0.1232   |     0.0444    |\n",
    "|                    |             |      Precision    |    0.0526     | 0.1232   |     0.0588    | \n",
    "|                    |             |      F1           |    0.0482     | 0.1233   |     0.0506    |\n",
    "|                    |Rouge-2      |      Recall       |    0.0000     | 0.0000   |     0.0000    |\n",
    "|                    |             |      Precision    |    0.0000     | 0.0000   |     0.0000    | \n",
    "|                    |             |      F1           |    0.0000     | 0.0000   |     0.0000   |\n",
    "|                    |Rouge-l      |      Recall       |    0.0444    | 0.0548   |     0.0444    |\n",
    "|                    |             |      Precision    |    0.0526     | 0.0548   |     0.0588    | \n",
    "|                    |             |      F1           |    0.0482     | 0.0548   |     0.0506    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09e966",
   "metadata": {},
   "source": [
    "Table 6: ROGUE Scores for \"Kafka on the Shore\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e55512",
   "metadata": {},
   "source": [
    "Apart from text by Frank Kafka, we input an excerpt from \"Kafka on the Shore\" by Haruki Murakami. The purpose of this was to explore how text from another author that shares a similar style to Frank Kafka would perform when tested on the text generation model. However, we observed lower BLEU and ROGUE scores than \"The Castle\" text. This could be due to different gramatical structures between Frank Kafka and Haruki Murakami. Both authors created stories in different time periods, Kafka in 1920s and Murakami in 1990. As observed in model results from \"The Castle\", the text generated after inputing the excerpt from \"Kafka on the Shore\" retained the main character, Gregor, from \"The Metamorphosis\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eeb137",
   "metadata": {},
   "source": [
    "### 10. Conclusions & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99de4dc",
   "metadata": {},
   "source": [
    "The optimized model showed better BLEU and ROUGE scores than the reference model. Having tuned various hyperparameters in the optimized model, the two most significant changes that improved model performance were introducing a bidirectional LSTM layer and decreasing the batch size from 128 to 64. Other less significant changes include increasing the number of hidden neurons from 100 to 150, increasing the number of epochs from 100 to 150 and adding a dropout layer with dropout rate of 0.2 after each LSTM layer to reduce overfitting. \n",
    "\n",
    "Increasing the sequence length of the input text resulted in lower BLEU and ROUGE scores, hence a shorter sequence length would have better model performance. When considering different types of input text, unseen text from the same author achieved higher BLEU and ROUGE scores than an unseen text from a different author. However, the output text still referenced the main character and settings from the training text. \n",
    "\n",
    "To improve the model, some of the following methods can be explored. \n",
    "1. Use multiple books from the same author to produce a larger collection of reference text.\n",
    "2. Use multiple books from several authors that have similar writing styles produced during a similar period.\n",
    "3. Use GloVe word embedding vectors to increase representation of words. \n",
    "4. Split the raw data based on sentences and pad each sentence to a fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6b6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
