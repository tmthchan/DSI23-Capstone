{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce80fe9",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70692484",
   "metadata": {},
   "source": [
    "### 2.5 Load Text - The Castle by Frank Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3b17c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load entire text file into memory and return it.\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r', \n",
    "                encoding='utf-8')    # open the file as read only\n",
    "    text = file.read()               # read all the text\n",
    "    file.close()                     # close the file\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d2ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was late evening when K. arrived. The village lay under deep\n",
      "snow. There was no sign of the Castle hill, fog and darkness\n",
      "surrounded it, not even the faintest gleam of light suggested the\n",
      "large Castle. K. stood a long time on the wooden bridge tha\n"
     ]
    }
   ],
   "source": [
    "# load document, Text_Cleaned.txt \n",
    "in_filename = '../data/castle_text.txt'\n",
    "doc = load_doc(in_filename)\n",
    "\n",
    "#preview first 250 characters \n",
    "print(doc[:250])                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39ce65",
   "metadata": {},
   "source": [
    "### 2.6 Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87f7645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a8f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to convert document into tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '-' with ' ' \n",
    "    doc = doc.replace('-', ' ')\n",
    "    # split doc into tokens by space\n",
    "    tokens = doc.split()           \n",
    "    # filter punctuated chars\n",
    "    re_punc = re.compile('[%s]'% re.escape(string.punctuation)) \n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]  \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()] \n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98e888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'late', 'evening', 'when', 'k', 'arrived', 'the', 'village', 'lay', 'under', 'deep', 'snow', 'there', 'was', 'no', 'sign', 'of', 'the', 'castle', 'hill', 'fog', 'and', 'darkness', 'surrounded', 'it', 'not', 'even', 'the', 'faintest', 'gleam', 'of', 'light', 'suggested', 'the', 'large', 'castle', 'k', 'stood', 'a', 'long', 'time', 'on', 'the', 'wooden', 'bridge', 'that', 'leads', 'from', 'the', 'main', 'road', 'to', 'the', 'village', 'gazing', 'upward', 'into', 'the', 'seeming', 'emptiness', 'then', 'he', 'went', 'looking', 'for', 'a', 'nights', 'lodging', 'at', 'the', 'inn', 'they', 'were', 'still', 'awake', 'the', 'landlord', 'had', 'no', 'room', 'available', 'but', 'extremely', 'surprised', 'and', 'confused', 'by', 'the', 'latecomer', 'he', 'was', 'willing', 'to', 'let', 'k', 'sleep', 'on', 'a', 'straw', 'mattress', 'in', 'the', 'taproom', 'k', 'agreed', 'to', 'this', 'a', 'few', 'peasants', 'were', 'still', 'sitting', 'over', 'beer', 'but', 'he', 'did', 'not', 'want', 'to', 'talk', 'to', 'anyone', 'got', 'himself', 'a', 'straw', 'mattress', 'from', 'the', 'attic', 'and', 'lay', 'down', 'by', 'the', 'stove', 'it', 'was', 'warm', 'the', 'peasants', 'were', 'quiet', 'he', 'examined', 'them', 'for', 'a', 'moment', 'with', 'tired', 'eyes', 'then', 'fell', 'asleep', 'yet', 'before', 'long', 'he', 'was', 'awakened', 'a', 'young', 'man', 'in', 'city', 'clothes', 'with', 'an', 'actors', 'face', 'narrow', 'eyes', 'thick', 'eyebrows', 'stood', 'beside', 'him', 'with', 'the', 'landlord', 'the', 'peasants', 'too', 'were', 'still', 'there', 'a', 'few', 'had', 'turned', 'their', 'chairs', 'around', 'to', 'see', 'and']\n"
     ]
    }
   ],
   "source": [
    "# convert document into tokens\n",
    "tokens = clean_doc(doc)\n",
    "# print first 200 tokens\n",
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573323ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens:  1052\n",
      "Number of unique tokens:  428\n"
     ]
    }
   ],
   "source": [
    "# print total number of tokens \n",
    "print('Total number of tokens: ', len(tokens))\n",
    "# convert tokens into a set and print the number of unique tokens\n",
    "print('Number of unique tokens: ', len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbd362f",
   "metadata": {},
   "source": [
    "### 2.7 Save Clean Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24389336",
   "metadata": {},
   "source": [
    "#### Sequence of 50 + 1 Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031c0bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 1001\n"
     ]
    }
   ],
   "source": [
    "# organize token list into sequences\n",
    "length = 50+1\n",
    "sequences = list()\n",
    "\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    #convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store each line in sequences\n",
    "    sequences.append(line)\n",
    "    \n",
    "# print total number of sequences\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a92ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eaee286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "out_filename = '../data/Text_Sequences_50_castle.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e4ffc",
   "metadata": {},
   "source": [
    "#### Sequence of 100 + 1 Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36239e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 951\n"
     ]
    }
   ],
   "source": [
    "# organize token list into sequences\n",
    "length = 100+1\n",
    "sequences = list()\n",
    "\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    #convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store each line in sequences\n",
    "    sequences.append(line)\n",
    "    \n",
    "# print total number of sequences\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc73af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "out_filename = '../data/Text_Sequences_100_castle.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455035b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
